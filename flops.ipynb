{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.resnet18_cifar import resnet18, NCM, ResNet, BasicBlock\n",
    "from utils.flops import calculate_flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "from torch import rand\n",
    "\n",
    "model = resnet18('seq-cifar10').cuda()\n",
    "# model = ResNet(block=BasicBlock, num_blocks=[2, 2, 2, 2], num_classes=10, nf=64).cuda()\n",
    "# input = rand(1, 3, 32, 32).cuda()\n",
    "input = (1, 3, 32, 32)\n",
    "\n",
    "flops = calculate_flops(model, input)\n",
    "print(f\"Total FLOPs: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18('seq-cifar10')\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "macs, params = profile(model, inputs=(input,))\n",
    "\n",
    "print(macs)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch-estimate-flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation               OPS       \n",
      "----------------------  --------  \n",
      "conv1                   2408448   \n",
      "bn1                     32768     \n",
      "relu                    32768     \n",
      "maxpool                 32768     \n",
      "layer1_0_conv1          2359296   \n",
      "layer1_0_bn1            8192      \n",
      "layer1_0_relu           8192      \n",
      "layer1_0_conv2          2359296   \n",
      "layer1_0_bn2            8192      \n",
      "add                     8192      \n",
      "layer1_0_relu_1         8192      \n",
      "layer1_1_conv1          2359296   \n",
      "layer1_1_bn1            8192      \n",
      "layer1_1_relu           8192      \n",
      "layer1_1_conv2          2359296   \n",
      "layer1_1_bn2            8192      \n",
      "add_1                   8192      \n",
      "layer1_1_relu_1         8192      \n",
      "layer2_0_conv1          1179648   \n",
      "layer2_0_bn1            4096      \n",
      "layer2_0_relu           4096      \n",
      "layer2_0_conv2          2359296   \n",
      "layer2_0_bn2            4096      \n",
      "layer2_0_downsample_0   131072    \n",
      "layer2_0_downsample_1   4096      \n",
      "add_2                   4096      \n",
      "layer2_0_relu_1         4096      \n",
      "layer2_1_conv1          2359296   \n",
      "layer2_1_bn1            4096      \n",
      "layer2_1_relu           4096      \n",
      "layer2_1_conv2          2359296   \n",
      "layer2_1_bn2            4096      \n",
      "add_3                   4096      \n",
      "layer2_1_relu_1         4096      \n",
      "layer3_0_conv1          1179648   \n",
      "layer3_0_bn1            2048      \n",
      "layer3_0_relu           2048      \n",
      "layer3_0_conv2          2359296   \n",
      "layer3_0_bn2            2048      \n",
      "layer3_0_downsample_0   131072    \n",
      "layer3_0_downsample_1   2048      \n",
      "add_4                   2048      \n",
      "layer3_0_relu_1         2048      \n",
      "layer3_1_conv1          2359296   \n",
      "layer3_1_bn1            2048      \n",
      "layer3_1_relu           2048      \n",
      "layer3_1_conv2          2359296   \n",
      "layer3_1_bn2            2048      \n",
      "add_5                   2048      \n",
      "layer3_1_relu_1         2048      \n",
      "layer4_0_conv1          1179648   \n",
      "layer4_0_bn1            1024      \n",
      "layer4_0_relu           1024      \n",
      "layer4_0_conv2          2359296   \n",
      "layer4_0_bn2            1024      \n",
      "layer4_0_downsample_0   131072    \n",
      "layer4_0_downsample_1   1024      \n",
      "add_6                   1024      \n",
      "layer4_0_relu_1         1024      \n",
      "layer4_1_conv1          2359296   \n",
      "layer4_1_bn1            1024      \n",
      "layer4_1_relu           1024      \n",
      "layer4_1_conv2          2359296   \n",
      "layer4_1_bn2            1024      \n",
      "add_7                   1024      \n",
      "layer4_1_relu_1         1024      \n",
      "avgpool                 512       \n",
      "fc                      513000    \n",
      "---------------------   -------   \n",
      "Input size: (1, 3, 32, 32)\n",
      "37,784,040 FLOPs or approx. 0.04 GFLOPs\n",
      "37784040\n",
      "28338030.0\n",
      "\n",
      "[['conv1', 2408448], ['bn1', 32768], ['relu', 32768], ['maxpool', 32768], ['layer1_0_conv1', 2359296], ['layer1_0_bn1', 8192], ['layer1_0_relu', 8192], ['layer1_0_conv2', 2359296], ['layer1_0_bn2', 8192], ['add', 8192], ['layer1_0_relu_1', 8192], ['layer1_1_conv1', 2359296], ['layer1_1_bn1', 8192], ['layer1_1_relu', 8192], ['layer1_1_conv2', 2359296], ['layer1_1_bn2', 8192], ['add_1', 8192], ['layer1_1_relu_1', 8192], ['layer2_0_conv1', 1179648], ['layer2_0_bn1', 4096], ['layer2_0_relu', 4096], ['layer2_0_conv2', 2359296], ['layer2_0_bn2', 4096], ['layer2_0_downsample_0', 131072], ['layer2_0_downsample_1', 4096], ['add_2', 4096], ['layer2_0_relu_1', 4096], ['layer2_1_conv1', 2359296], ['layer2_1_bn1', 4096], ['layer2_1_relu', 4096], ['layer2_1_conv2', 2359296], ['layer2_1_bn2', 4096], ['add_3', 4096], ['layer2_1_relu_1', 4096], ['layer3_0_conv1', 1179648], ['layer3_0_bn1', 2048], ['layer3_0_relu', 2048], ['layer3_0_conv2', 2359296], ['layer3_0_bn2', 2048], ['layer3_0_downsample_0', 131072], ['layer3_0_downsample_1', 2048], ['add_4', 2048], ['layer3_0_relu_1', 2048], ['layer3_1_conv1', 2359296], ['layer3_1_bn1', 2048], ['layer3_1_relu', 2048], ['layer3_1_conv2', 2359296], ['layer3_1_bn2', 2048], ['add_5', 2048], ['layer3_1_relu_1', 2048], ['layer4_0_conv1', 1179648], ['layer4_0_bn1', 1024], ['layer4_0_relu', 1024], ['layer4_0_conv2', 2359296], ['layer4_0_bn2', 1024], ['layer4_0_downsample_0', 131072], ['layer4_0_downsample_1', 1024], ['add_6', 1024], ['layer4_0_relu_1', 1024], ['layer4_1_conv1', 2359296], ['layer4_1_bn1', 1024], ['layer4_1_relu', 1024], ['layer4_1_conv2', 2359296], ['layer4_1_bn2', 1024], ['add_7', 1024], ['layer4_1_relu_1', 1024], ['avgpool', 512], ['fc', 513000]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from pthflops import count_ops\n",
    "\n",
    "# Create a network and a corresponding input\n",
    "device = 'cuda:0'\n",
    "model = resnet18().to(device)\n",
    "inp = torch.rand(10500,3,32,32).to(device)\n",
    "\n",
    "# Count the number of FLOPs\n",
    "ops, all_data = count_ops(model, inp)\n",
    "\n",
    "print(ops)\n",
    "print(ops * 0.75)\n",
    "print()\n",
    "print(all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
